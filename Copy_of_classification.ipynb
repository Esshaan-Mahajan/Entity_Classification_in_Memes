{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR1ErWeRCe0Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z06JJ9OP2G7",
        "outputId": "9aeb705d-5ebc-40b3-a40b-b542fd3f9cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9LO5nG0glDD"
      },
      "outputs": [],
      "source": [
        "root_path = 'gdrive/My Drive/iiitd_research'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fd60Y0oCzAp"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLrEEWoYSUEA",
        "outputId": "ad698999-be1a-47d7-b5c1-95a3b9f3acd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'gdrive', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir())\n",
        "os.chdir('gdrive/My Drive/iiitd_research')\n",
        "#!unzip 'constraint22_dataset_covid19.zip'\n",
        "# print(os.getcwd())\n",
        "# print(os.listdir('./content/covid_meme_data'))\n",
        "\n",
        "\n",
        "#os.chdir('/content/view?usp=sharing')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTcqDpFbXNJA"
      },
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUDchTNODO_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "f5039eb8-86f0-4ddb-d070-0fffc0f237ea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-efba83441abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ViT-L14trainembed.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrainembed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'map_location' is an invalid keyword argument for load()"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "with open(\"ViT-L14trainembed.pickle\", 'rb') as f:\n",
        "    trainembed = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjpHUfOYnpum"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"uspoliticsViT-L14trainembed.pickle\", 'rb') as f:\n",
        "    ustrainembed = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgibjeyEDO81"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# with open(\"berttrainembeddings.pickle\", 'rb') as f:\n",
        "#     berttrain = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItlorPb5WcS5"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# with open(\"bertentitytrainembeddings.pickle\", 'rb') as f:\n",
        "#     berttrainentity = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suKXtGR-DO6u"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"trainlabels.pickle\", 'rb') as f:\n",
        "    trainlabels = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2QKFxbbnzfc"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"uspoliticslabels.pickle\", 'rb') as f:\n",
        "    ustrainlabels = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxouYQzYdhln",
        "outputId": "dec90217-cd26-448c-ad1c-3fad97f92157"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7234, 2304])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "trainembed.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "444bdXduYr9w"
      },
      "source": [
        "cancatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0cKf3lDdTw_"
      },
      "outputs": [],
      "source": [
        "# berttrain = torch.Tensor(berttrain).cuda()\n",
        "# berttrainentity = torch.Tensor(berttrainentity).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oIsQYVcYrZR"
      },
      "outputs": [],
      "source": [
        "# input_tensor =torch.cat((trainembed, berttrain, berttrainentity), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCdCrvy5XPKp"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qLLPGSnWGVp"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"ViT-L14testembeddings.pickle\", 'rb') as f:\n",
        "    testembed = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAINSWxcn608"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"uspoliticsViT-L14testembed.pickle\", 'rb') as f:\n",
        "    ustestembed = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6evdBQ5WVPw"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# with open(\"berttestembeddings.pickle\", 'rb') as f:\n",
        "#     berttest = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMP-KtlDXd1f"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# with open(\"berttestentityembeddings.pickle\", 'rb') as f:\n",
        "#     berttestentity = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J7pejBFWVHB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"testlabels.pickle\", 'rb') as f:\n",
        "    testlabels = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIPFXamccowr"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"uspoliticstestlabels.pickle\", 'rb') as f:\n",
        "    ustestlabels = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avQQLBHlZUm3"
      },
      "source": [
        "concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM5ufeencPPG"
      },
      "outputs": [],
      "source": [
        "# berttest = torch.Tensor(berttest).cuda()\n",
        "# berttestentity = torch.Tensor(berttestentity).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CajXSnkNZUXf"
      },
      "outputs": [],
      "source": [
        "# test_tensor = torch.cat((testembed, berttest, berttestentity), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4b9totloXbj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3lupsUGrFEU"
      },
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5zUIy7eoXY0",
        "outputId": "b9a4d1d5-72c9-4a59-d320-a60d5eb9611b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7234, 2304])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "trainembed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm1eG8XboW7p",
        "outputId": "e12eb07e-05b3-4a49-bc21-e3f054842706"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10280, 2304])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "ustrainembed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1gUaJl4pBlb"
      },
      "outputs": [],
      "source": [
        "input_tensor = torch.cat((trainembed,ustrainembed), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gv6h2NKpbUa",
        "outputId": "b85be295-676c-4f94-f3b5-c5b26aaa8e57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([17514, 2304])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "(input_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2ppWkpcp1cu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLdUjxjRpiyE"
      },
      "outputs": [],
      "source": [
        "ytrainlabels =trainlabels + ustrainlabels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHcpmFkbrDdV"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pDxF5K9qkQo"
      },
      "outputs": [],
      "source": [
        "test_tensor = torch.cat((testembed,ustestembed), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2xEvIthrOVY",
        "outputId": "6dcb4baa-1708-49f3-d098-ee6a5cf5633c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2433, 2304])\n"
          ]
        }
      ],
      "source": [
        "print(test_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ajlBqtjqZlC"
      },
      "outputs": [],
      "source": [
        "ytestlabels = testlabels + ustestlabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnoOEtdCq-VT",
        "outputId": "085bff8e-5f11-41cb-e5ab-785c1782e844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2433\n"
          ]
        }
      ],
      "source": [
        "print(len(ytestlabels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZKyliY_tWjU"
      },
      "source": [
        "# **Creating final data into train val test for classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah42_IptEER2"
      },
      "outputs": [],
      "source": [
        "\n",
        "xtrain=input_tensor\n",
        "xval=test_tensor\n",
        "ytrain=ytrainlabels\n",
        "yval=ytestlabels\n",
        "\n",
        "# xtrain= trainembed\n",
        "# xval=testembed\n",
        "# ytrain=trainlabels\n",
        "# yval=testlabels\n",
        "\n",
        "\n",
        "# xtrain=input_tensor[:800]\n",
        "# xval=input_tensor[800:1000]\n",
        "# ytrain=labels[:800]\n",
        "# yval=labels[800:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dn4FQqHm9rN",
        "outputId": "ea181de1-609a-4a6d-c0c5-6a2873a30752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([17514, 2304])\n",
            "torch.Size([2433, 2304])\n",
            "<class 'torch.Tensor'>\n",
            "17514\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(xtrain.shape)\n",
        "print(xval.shape)\n",
        "#xtrain=xtrain.numpy()\n",
        "print(type(xtrain))\n",
        "print(len(ytrain))\n",
        "#print(yval.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_UiUi6q8vyj"
      },
      "source": [
        "# Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD8d_mf1RXBw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "xtrain2 = torch.Tensor.cpu(xtrain)\n",
        "xval2 = torch.Tensor.cpu(xval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSJL_ZkgN91H"
      },
      "source": [
        "Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "eNGekYfRN9aB",
        "outputId": "39540996-1099-445d-cb1e-4b8d2b3db50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fscore for criteria  gini  max feat  sqrt  classwt  balanced  is  0.309567298193234\n",
            "fscore for criteria  gini  max feat  sqrt  classwt  balanced_subsample  is  0.2920540885257357\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ea60a4c06e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fscore for criteria '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' max feat '\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' classwt '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' is '\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "criteria =['gini', 'entropy','log_loss']\n",
        "maxfeat = ['sqrt', 'log2', None]\n",
        "clsswt = ['balanced', 'balanced_subsample',None]\n",
        "\n",
        "for x in criteria:\n",
        "  for y in maxfeat:\n",
        "    for z in clsswt:\n",
        "\n",
        "\n",
        "      ypred = RandomForestClassifier(criterion=x,class_weight = z, max_features=y).fit(xtrain2, ytrain).predict(xval2)\n",
        "      print('fscore for criteria ',x,' max feat ' ,y,' classwt ',z,' is ' ,f1_score(yval, ypred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJhM2OnowvFi"
      },
      "source": [
        "k neighbors classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H64RM-MNrc7Q",
        "outputId": "5e082a9a-d153-4021-8e4d-61dee50ee8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fscore for k = 1 0.4435348968672381\n",
            "fscore for k = 2 0.4151042451190864\n",
            "fscore for k = 3 0.4342139782838559\n",
            "fscore for k = 4 0.43545372399363635\n",
            "fscore for k = 5 0.45466603824247365\n",
            "fscore for k = 6 0.47703285531098594\n",
            "fscore for k = 7 0.4500812385238019\n",
            "fscore for k = 8 0.4595731690949523\n",
            "fscore for k = 9 0.4614387504823604\n",
            "fscore for k = 10 0.4644042091360837\n",
            "fscore for k = 11 0.4658872011559882\n",
            "fscore for k = 12 0.44638930704297486\n",
            "fscore for k = 13 0.44208810575443175\n",
            "fscore for k = 14 0.4413028261690301\n",
            "fscore for k = 15 0.4318766250978038\n",
            "fscore for k = 16 0.4261013926270365\n",
            "fscore for k = 17 0.4338432284064171\n",
            "fscore for k = 18 0.4270272165562454\n",
            "fscore for k = 19 0.4189143279568811\n",
            "fscore for k = 20 0.41718321409581577\n",
            "fscore for k = 21 0.41572218847349907\n",
            "fscore for k = 22 0.4052602990844204\n",
            "fscore for k = 23 0.40011641733669834\n",
            "fscore for k = 24 0.40513394073213327\n",
            "fscore for k = 25 0.39405484192614093\n",
            "fscore for k = 26 0.38753585030259097\n",
            "fscore for k = 27 0.37251229584774503\n",
            "fscore for k = 28 0.36685803123454175\n",
            "fscore for k = 29 0.3604315405119862\n",
            "max fscore : 0.47703285531098594\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "xtrain2 = torch.Tensor.cpu(xtrain)\n",
        "xval2 = torch.Tensor.cpu(xval)\n",
        "maxfscore = 0\n",
        "for k in range(1,30):\n",
        "  neigh = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "  neigh.fit(xtrain2, ytrain)\n",
        "  ypredict = neigh.predict(xval2)\n",
        "  acc = (sum(ypredict==yval))/len(yval)\n",
        "  #print('acc for k =',k,acc)\n",
        "  fscore = f1_score(yval, ypredict, average='macro')\n",
        "  if maxfscore<fscore:\n",
        "    maxfscore = fscore\n",
        "  print('fscore for k =',k,fscore)\n",
        "print('max fscore :',maxfscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD_LSFKjvDIo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T34Lic9hugRp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajYxyXzyvt-n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPrLtBPdwaE_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZN_34pqwVp1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD-zHr2ajVsh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvR8Ydtxm1D"
      },
      "source": [
        "decision tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z27BNdFAv0d-",
        "outputId": "7b8a4539-ce0f-4fd8-91c8-4749acb3509c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fscore for best max features = 1 0.2820273946910153\n",
            "fscore for random max features = 1 0.3001052601016617\n",
            "fscore for best max features = 2 0.291101509029024\n",
            "fscore for random max features = 2 0.2936383385339828\n",
            "fscore for best max features = 3 0.3358011581169055\n",
            "fscore for random max features = 3 0.32060715194459655\n",
            "fscore for best max features = 10 0.3371920245694242\n",
            "fscore for random max features = 10 0.31171989164001135\n",
            "fscore for best max features = 1000 0.32511024335628275\n",
            "fscore for random max features = 1000 0.3275854493577196\n",
            "fscore for best max features = 100 0.3248163835398828\n",
            "fscore for random max features = 100 0.3504511690345421\n",
            "fscore for best max features = auto 0.3164978490706292\n",
            "fscore for random max features = auto 0.3549378166314564\n",
            "fscore for best max features = sqrt 0.3374185167576046\n",
            "fscore for random max features = sqrt 0.3446885088466209\n",
            "fscore for best max features = log2 0.32239019400078217\n",
            "fscore for random max features = log2 0.3265804412462472\n",
            "max fscore : 0.4694461151207343\n"
          ]
        }
      ],
      "source": [
        "from sklearn import tree\n",
        "max_feature = [1,2,3,10,1000,100,'auto','sqrt','log2']\n",
        "for x in max_feature:\n",
        "  clf = tree.DecisionTreeClassifier(splitter = 'best',max_features=x)\n",
        "  clf = clf.fit(xtrain2, ytrain)\n",
        "  ypred=clf.predict(xval2)\n",
        "\n",
        "  acc =(sum(ypred==yval))/len(yval)\n",
        "  #print('acc for k =',k,acc)\n",
        "  fscore = f1_score(yval, ypred, average='macro')\n",
        "  if maxfscore<fscore:\n",
        "    maxfscore = fscore\n",
        "  print('fscore for best max features =',x,fscore)\n",
        "  clf = tree.DecisionTreeClassifier(splitter = 'random',max_features=x)\n",
        "  clf = clf.fit(xtrain2, ytrain)\n",
        "  ypred=clf.predict(xval2)\n",
        "\n",
        "  acc =(sum(ypred==yval))/len(yval)\n",
        "  #print('acc for k =',k,acc)\n",
        "  fscore = f1_score(yval, ypred, average='macro')\n",
        "  if maxfscore<fscore:\n",
        "    maxfscore = fscore\n",
        "  print('fscore for random max features =',x,fscore)\n",
        "print('max fscore :',maxfscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJrJZnD7rcyv"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K3IOBDprclu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5956TqRBxY5p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKQB8YrGyTPH"
      },
      "source": [
        "Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LSQKmOjxY3A",
        "outputId": "514bae90-9e25-4635-e8e2-6e3b110a0777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fscore at max_iter 1000 loss hinge penalty l2 =  0.39189890021092366\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "loss = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']#'squared_error', 'huber', 'epsilon_insensitive','squared_epsilon_insensitive']\n",
        "pen =['l2', 'l1', 'elasticnet']\n",
        "n = 1000\n",
        "maxfscore = 0\n",
        "for x in loss:\n",
        "  for y in pen:\n",
        "    cl = SGDClassifier(loss=x, penalty=y, max_iter=n)\n",
        "    cl.fit(xtrain2, ytrain)\n",
        "    ypre = cl.predict(xval2)\n",
        "    acc  = (sum(ypre==yval))/len(yval)\n",
        "\n",
        "    fscore = f1_score(yval, ypre, average='macro')\n",
        "    if maxfscore<fscore:\n",
        "      maxfscore = fscore\n",
        "    print('fscore at max_iter',n,'loss',x,'penalty',y ,'= ',fscore)\n",
        "print('maxfscore',maxfscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SaMiYtiSx6Jv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FHd8dofox6HR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IGqWyQvjSsaF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-ouUHrt3hP3"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC()\n",
        "clf.fit(xtrain2, ytrain)\n",
        "ypred = clf.predict(xval2)\n",
        "acc  = (sum(ypred==yval))/len(yval)\n",
        "\n",
        "fscore = f1_score(yval, ypred, average='macro')\n",
        "print(fscore)"
      ],
      "metadata": {
        "id": "zIzblxi51I6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "Yv4Yj8Cc2sGS",
        "outputId": "3dd0edf8-2305-449a-c689-2d7575b327c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fscore at kernal linear shape ovo gamma scale classwt balanced  =  0.38858058861379885\n",
            "fscore at kernal linear shape ovo gamma scale classwt None  =  0.39262374456887006\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-56c8a2227d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0macc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "maxfscore = 0\n",
        "from sklearn import svm\n",
        "kernal  = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
        "pen = ['ovo', 'ovr']\n",
        "gamma = ['scale', 'auto']\n",
        "class_weight = ['balanced', None]\n",
        "for x in kernal:\n",
        "  for y in pen:\n",
        "    for z in gamma:\n",
        "      for a in class_weight:\n",
        "\n",
        "        clf = svm.SVC(kernel =x,decision_function_shape = y,gamma = z,class_weight = a)\n",
        "        clf.fit(xtrain2, ytrain)\n",
        "        ypred = clf.predict(xval2)\n",
        "        acc  = (sum(ypred==yval))/len(yval)\n",
        "\n",
        "        fscore = f1_score(yval, ypred, average='macro')\n",
        "        if maxfscore<fscore:\n",
        "          maxfscore = fscore\n",
        "        print('fscore at kernal',x,'shape',y,'gamma',z ,'classwt',a,' = ',fscore)\n",
        "print('maxfscore',maxfscore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZX8BneKM2sB_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ITLxzW5k2r5q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U9HKpab72r29"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36eyp3TgsDob"
      },
      "source": [
        "one vs rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GwZkv8yasE3m"
      },
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "ypred  = OneVsRestClassifier(LinearSVC(random_state=0,max_iter =1000),).fit(xtrain2, ytrain).predict(xval2)\n",
        "print(f1_score(yval, ypred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVSQ6g3nrjbn"
      },
      "source": [
        "one vs one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YkvJOWUFDSUm"
      },
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "ypred = OneVsOneClassifier(LinearSVC(random_state=0,max_iter =100)).fit(xtrain2, ytrain).predict(xval2)\n",
        "print(f1_score(yval, ypred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM46AXc4sh81"
      },
      "source": [
        "output code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9WPNBfqeshjT"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.multiclass import OutputCodeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "clf = OutputCodeClassifier(LinearSVC(random_state=0,max_iter = 100),code_size=2, random_state=0)\n",
        "ypred = clf.fit(xtrain2, ytrain).predict(xval2)\n",
        "print(f1_score(yval, ypred, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aFl1d8xPDSSv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQowA-iqiRLa"
      },
      "source": [
        "Very basic NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmVbFjfliRLj",
        "outputId": "789e2fac-a66a-4f51-b8fe-7f3fa755924a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "ytrain =torch.tensor(ytrain).cuda()\n",
        "yval =torch.tensor(yval).cuda()\n",
        "xtrain =torch.tensor(xtrain).cuda()\n",
        "xval =torch.tensor(xval).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ESwG95fL-T56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "HnnEG2XtiRLm",
        "outputId": "7e1ec263-c926-41bb-9fa0-8649e5635181"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1b5e69d90332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xtrain' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset\n",
        "epoc = [10,20,30,40,50,60,70,80]\n",
        "for myepoc in epoc:\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "  input_size = 2304\n",
        "  hidden_size = 512\n",
        "  num_classes = 4\n",
        "  num_epochs = myepoc\n",
        "  batch_size = 32\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  train_dataset = TensorDataset(xtrain,ytrain)\n",
        "\n",
        "  test_dataset = TensorDataset(xval,yval)\n",
        "\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=False)\n",
        "\n",
        "  class NeuralNet(nn.Module):\n",
        "      def __init__(self, input_size, hidden_size, num_classes):\n",
        "          super(NeuralNet, self).__init__()\n",
        "          self.input_size = input_size\n",
        "          self.l1 = nn.Linear(input_size, 1024)\n",
        "          self.relu = nn.ReLU()\n",
        "          self.l2 = nn.Linear(1024, hidden_size)\n",
        "          self.relu = nn.ReLU()\n",
        "          # self.l3 = nn.Linear(hidden_size,128)\n",
        "          # self.relu = nn.ReLU()\n",
        "          self.l4 = nn.Linear(hidden_size,32)\n",
        "          self.relu = nn.ReLU()\n",
        "          self.l5 = nn.Linear(32, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "          out = self.l1(x)\n",
        "          out = self.relu(out)\n",
        "          out = self.l2(out)\n",
        "          out = self.relu(out)\n",
        "          # out = self.l3(out)\n",
        "          # out = self.relu(out)\n",
        "          out = self.l4(out)\n",
        "          out = self.relu(out)\n",
        "          out = self.l5(out)\n",
        "\n",
        "\n",
        "          # no activation and no softmax at the end\n",
        "          return out\n",
        "\n",
        "  nnmodel = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(nnmodel.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  n_total_steps = len(train_loader)\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss=0.0\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      for data, labels2 in train_loader:#xtrain.cuda(), ytrain.cuda()\n",
        "\n",
        "          # Clear the gradients\n",
        "          optimizer.zero_grad()\n",
        "          # Forward Pass\n",
        "          target = nnmodel(data)\n",
        "          # Find the Loss\n",
        "          loss = criterion(target,labels2)\n",
        "          # Calculate gradients\n",
        "          loss.backward()\n",
        "          # Update Weights\n",
        "          optimizer.step()\n",
        "          # Calculate Loss\n",
        "          train_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss / n_total_steps} \\t\\t Validation Loss: {train_loss / len(test_loader)}')\n",
        "\n",
        "\n",
        "  #nnmodel()\n",
        "\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  prediction =[]\n",
        "  with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          testdata, tralabels = data\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = nnmodel(testdata)\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          prediction.append(predicted)\n",
        "          total += tralabels.size(0)\n",
        "\n",
        "  predictions = prediction[0]\n",
        "  k=0\n",
        "  for i in prediction:\n",
        "\n",
        "    predictions = torch.cat((predictions,i),0)\n",
        "    k=k+1\n",
        "\n",
        "  predictions =predictions[32:]\n",
        "\n",
        "  ypred = predictions.cpu()\n",
        "  yval =yval.cpu()\n",
        "\n",
        "\n",
        "  print('Num of epochs ',num_epochs,' -> ',f1_score(yval, ypred, average='macro'))\n",
        "\n",
        "  ypred = predictions.cuda()\n",
        "  yval =yval.cuda()\n",
        "\n",
        "        #correct += (predicted == tralabels).sum().item()\n",
        "\n",
        "    # for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "    #     images = images.to(device)\n",
        "    #     labels = labels.to(device)\n",
        "\n",
        "    #     # Forward pass\n",
        "    #     outputs = model(images)\n",
        "    #     loss = criterion(outputs, labels)\n",
        "\n",
        "    #     # Backward and optimize\n",
        "    #     optimizer.zero_grad()\n",
        "    #     loss.backward()\n",
        "    #     optimizer.step()\n",
        "\n",
        "        # if (i+1) % 100 == 0:\n",
        "        #     print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y4CDOBUqByHa"
      },
      "outputs": [],
      "source": [
        "predictions = prediction[0]\n",
        "k=0\n",
        "for i in prediction:\n",
        "\n",
        "  predictions = torch.cat((predictions,i),0)\n",
        "  k=k+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K91eleACDYJU"
      },
      "outputs": [],
      "source": [
        "print((predictions[:]))\n",
        "predictions =predictions[32:]\n",
        "print(len(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iH78wMxQEvU-"
      },
      "outputs": [],
      "source": [
        "ypred = predictions.cpu()\n",
        "yval =yval.cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r1J8YewGEfOa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(yval, ypred, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rcTb3uMEDSQm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}